# Q(y) = X alpha + Z beta + g(X theta + Z gamma)

module qgplsim
	include("supportFunctions.ji")
	include("localLinear_quantReg.ji")
	using LinearAlgebra, Distributions, Random, Statistics
    using GLM, DataFrames, CSV, CategoricalArrays
	using Clustering

	mutable struct model
		X::Matrix{Float64}
		Z # ::Matrix # {Float64}
		y::Vector{Float64}
		categ::Vector # cannot ensure z is Int 
		index::Dict
		quantileNum
        widthExp::Float64
		alpha
		gamma
		theta # ::Vector{Float64}
		beta # ::Vector{Float64}
        dGz
		function model(X, Z, y, τ = [0.5], widthExp = -0.17)
			categ, index = collection(Z)
            n, p = size(X)
            n, q = size(Z)
            alpha, theta = zeros(p), zeros(p)
            beta, gamma = zeros(q), zeros(q)
			new(X, Z, y, categ, index, τ, widthExp, alpha, gamma, theta, beta)
		end
    
    
        function model(df::DataFrame, name_x::Vector{Symbol}, name_z::Vector{Symbol}, name_y::Symbol, τ = [0.5], widthExp = -0.17)

            X = scaler(Array(df[!, name_x]))
            Z = Array(df[!, name_z])
            y = Array(df[!, name_y])

            Zb, zmap = categ_binary(Z)
            categ, index = collection(Zb)
            alpha, theta = zeros(p), zeros(p)
            beta, gamma = zeros(q), zeros(q)
			new(X, Zb, y, categ, index, τ, widthExp, alpha, gamma, theta, beta)
        
        end
	end
    
    function print_model(m::model)
        println("alpha => ", round.(m.alpha, digits = 4))
        println("theta => ", round.(m.theta, digits = 4))
        println("gamma => ", round.(m.gamma, digits = 4))
        println("beta => ", round.(m.beta, digits = 4))
    end

	function predict(m::model, x::Matrix, z::Vector, dv = 0) # d = 0 Gz, d = 1 dGz, d = 2  ada_Gz
		v = x * m.theta + z .* m.gamma 
		vm = m.X * m.theta + m.Z .* m.gamma
		ym = m.y - m.X * m.alpha - m.Z .* m.beta
		n,p = size(x)
		res = zeros(n)
        res = vec_Gz(v, vm, ym, dv, m.quantileNum,  m.widthExp, method)
		
	end

	function predict(m::model, x::Matrix, z::Matrix, dv = 0, method = "qr")

		v = x * m.theta + z * m.gamma 
  		vm = m.X * m.theta + m.Z * m.gamma  
		ym = m.y - m.X * m.alpha - m.Z * m.beta
		n,p = size(x)
		res = zeros(n)
        res = vec_Gz(v, vm, ym, dv, m.quantileNum,  m.widthExp, method)

	end
	function estimator(data::model, method = "qr")
		theta_init(data, method)
        alpha_init(data)
        # println("init estimation of theta, alpha: \n ")
        # println("theta => ", data.theta)
        # println("alpha => ", data.alpha, "\n")
    
        # gv, dgv = beta_estimator(data)
        # theta_estimator(data, gv, dgv)
        # alpha_estimator(data)
    
        if data.widthExp == 0
            data.widthExp = bandwidth_selection(data)
        end
		gamma_estimator(data, method)
        beta_estimator(data)
	end

	function theta_init(mode::model, method)

        X, y, tau = mode.X, mode.y, mode.quantileNum
        n, p = size(X)
        categ, index = mode.categ,  mode.index
        ncateg = index.count
        
        # Gz = zeros(n)
        dGz = zeros(n, p)

        for k in 1:ncateg
            zk = categ[k]
            ind_zk = index[zk]
            nk = length(ind_zk)
            yk = y[ind_zk]
            Xk = X[ind_zk, :]

            ht = mean(var(Xk, dims = 1))
			h = ones(p) .* nk^(-1/(2p + 10))
            h = h .* ht
			# for i in 1:p
			#    h[i] = h[i] * ht[i] 
			# end

			for i in 1:nk 
				Xzi = Xk[i, :]
				Xi = Xk - (Xzi)
				ind = Vector(1:nk)
				popat!(ind, i)
				Xi = Xi[ind, :]
				yzi = yk[ind]
				KerVal = ker(Xi, h)
				Xi = [ones(nk - 1) Xi]
                wi = localLinear_quantReg.solver(yzi, Xi, KerVal, tau, method)

                # Gz[ind_zk[i]] = wi[1]
				dGz[ind_zk[i],:] = wi[3:end]
			end
        end
            mode.dGz = dGz

            nij = Int(n * (n - 1) / 2)
            ∑ = zeros(nij, p)
            ij = 1
            for i in 1:n-1
                for j in (i + 1):n
                    ∑[ij, :] = dGz[i, :] - dGz[j, :]
                    ij = ij + 1
                end
            end
            
            ∑n = ∑' * ∑
            eigval = eigvals(∑n)
            ind_eigvec = argmax(eigval)
            theta = eigvecs(∑n)[:, ind_eigvec]
            theta = theta / norm(theta)
            sg = sign(theta[1])
            mode.theta =  theta .* sg
    end
    
    function alpha_init(m::model)
            
            n = length(m.y)
            dgz = m.dGz * m.theta
            alpha = sum(m.dGz - kron(dgz, m.theta'), dims = 1)
            m.alpha = alpha[1,:]/n
    
    end


    function theta_estimator(m::model, gv, dgv)
        n, p = size(m.X)
        h = ones(p) .* n^(-1 / 2(p + 5))
        theta = zeros(p)
        y = m.y - m.Z*m.beta - m.X * m.alpha
        # b = zeros(n + 1)
        for k in 1:n
            ind = Vector(1:n)
            popat!(ind, k)
            yj = y .- gv[k]
            Xij = (m.X - m.X[k, :]).*dgv
            yj, Xij = yj[ind], Xij[ind, :]
            Wij = ker(Xij, h)
            # Xij = hcat(ones(n - 1, 1), Xij) 
            res = localLinear_quantReg.solver(yj, Xij, Wij, m.quantileNum) 
            thetak = res[2:end]
            # b[k] = res[2]
            theta = theta + thetak
        end
        m.theta = theta / norm(theta)

    end

    function alpha_estimator(m::model)
        n, p = size(m.X)
        alpha, b = zeros(p), zeros(n)
        v = m.X*m.theta
        h = var(v)*(n)^(m.widthExp)
        y = m.y - m.Z*m.beta
        for k in 1:n
            ind = Vector(1:n)
            popat!(ind, k)
            vij = v .- v[k]
            vij = vij[ind] 
            vk = hcat(ones(n - 1),  vij)
            wk = ker(vij, h)
            res = localLinear_quantReg.solver(y[ind], vk, wk, m.quantileNum)
            b[k] = res[2]
        end
        alpha = pinv(m.X'*m.X)*m.X'*b

    end



	function gamma_estimator(data::model, method)
    
        if typeof(data.Z) <: Vector
            n = length(data.Z)
            q = 1
        else
            n, q = size(data.Z)
        end

        dz = 1
		gamma = zeros(q)
		X = data.X
		v = X * data.theta
		y = data.y  - data.X * data.alpha  # - data.Z * data.beta # c1 = 0
		τ = data.quantileNum
        hp = data.widthExp
		index = deepcopy(data.index)
		categ = collect(index)
		ncateg = index.count
		vv0, vv1 = -1e5, 1e5
		v0, v1 = -1e5, 1e5
		c0, c1 = 1, -1
        hz = zeros(ncateg)
			C0 = zeros(ncateg)
			C1 = zeros(ncateg)
			for k in 1:ncateg
				vk = v[categ[k][2]]
				min_vk = minimum(vk)
				max_vk = maximum(vk)
				hz[k] = (length(vk))^(hp) * std(vk)    # * (max_vk - min_vk)/2
				vmin = min_vk 
				vmax = max_vk 
				if vv0 < vmin
					vv0 = vmin
				end

				if vv1 > vmax
					vv1 = vmax
				end
			end
                tail = mean(hz)
                # println((vv1 - vv0)/tail)
                v0 = vv0 + 2.0 * tail
                v1 = vv1 - 2.0 * tail

				for k in 1:ncateg
					vk = v[categ[k][2]]
					yk = y[categ[k][2]]

					v_ = vk[vk .> v1]
					if v_ == []
						v_ = [v1]
					end
					_v = vk[vk .< v0]
					if _v == []
						_v = [v0]
					end
					
					v_ = minimum(v_) # vk[vk .> v1]
					_v = maximum(_v) # vk[vk .< v0]

					C0[k] = Gz(_v, vk, yk, dz, τ, hp, method)
					C1[k] = Gz(v_, vk, yk, dz, τ, hp, method)
				end
			
				c0 = maximum(C0)
				c1 = minimum(C1)



		for i in 1:ncateg
			ΔdJ = zeros(ncateg - 1)
            C0i, C1i = max.(C0, C0[i]), min.(C1, C1[i])
            popat!(C0i, i)
            popat!(C1i, i)
			ΔZ = transpose(hcat(keys(index)...))
			categ = collect(index)
			ΔZ = ΔZ[1:end, :] - ΔZ[i, :]
			tdz = ΔZ[i, :]
			ΔZ[i, :] = ΔZ[1, :]
			ΔZ = ΔZ[2:end, :]
			zi = categ[i, :]
			categ[i, :] = categ[1, :]
			categ[1, :] = zi
			z1 = categ[1][1]
        
			vz = v[categ[1][2]]
			yz = y[categ[1][2]]
			dg1(u) = Gz(u, vz, yz, dz, τ, hp, method)
            for k in 1:ncateg - 1
                ΔdJ[k] = ΔdJ[k] .- glquad(dg1, v0, v1, C0i[k], C1i[k])
            end
            # println(ΔdJ)
            
			for k in 1:ncateg - 1
				
				vk = v[categ[k + 1][2]]
				yk = y[categ[k + 1][2]]
				dgk(u) = Gz(u, vk, yk, dz, τ, hp, method)
				ΔdJ[k] = ΔdJ[k] + glquad(dgk, v0, v1, C0i[k], C1i[k])
				ΔdJ[k] = ΔdJ[k] ./ (C1i[k] - C0i[k])
            
			end
			gammai = inv(transpose(ΔZ)*ΔZ + 0.000001 .* I(q)) * transpose(ΔZ) * ΔdJ 
      		gamma = gamma + gammai 
            
			# estimation for β    
# 			d1 =  sum(z1 .* gammai)
#             p1 = Vector(LinRange(v0, v1, 11))
# 			yp1 = vec_Gz(p1, vz, yz, 0, τ, hp)
# 			ΔJ = zeros(ncateg - 1)
        
#             for k in 1:ncateg - 1
# 				zk = categ[k][1]
# 				vk = v[categ[k + 1][2]]
# 				yk = y[categ[k + 1][2]]
#                 dk =  sum(zk .* gammai)
#                 pk = Vector(LinRange(v0 + d1 - dk, v1 + d1 - dk, 11))
#                 ypk = vec_Gz(pk, vk, yk, 0, τ, hp)
#                 ΔJ[k] = mean(yp1 - ypk)               
           
#             end

# 			ΔZ = - ΔZ
# 			betai = inv(transpose(ΔZ)*ΔZ + 0.000001 * I(q)) * transpose(ΔZ) * ΔJ # /abs(v1 - v0)
#             # println(betai)
# 			push!(beta, betai)
		end
    
		data.gamma = gamma/ncateg # .- 0.5
	end
    function beta_estimator(m::model)
        v = m.X*m.theta  + m.Z*m.gamma
        n, q = size(m.Z)
        h = var(v)*(n)^(m.widthExp)
        y = m.y - m.X*m.alpha
        gv, dgv = zeros(n), zeros(n)
        categ = collect(m.index)
        ncateg = length(categ)
        nzz = Int((ncateg - 1) * (ncateg) / 2)
        A, b = zeros(nzz + 1, q), zeros(nzz + 1)
        A[1, :] = m.gamma
        t = 2
        for i in 1:(ncateg - 1)
    
            zi, indi = categ[i][1], categ[i][2]
            ni = length(indi)
            yi = y[indi]
            vi = v[indi]
            for j in (i + 1):ncateg
                # if j != i
                    zj, indj = categ[j][1], categ[j][2]
                    nj = length(indj)
                    vj = v[indj]
                    yj = y[indj]
                    bij = 0
                    for k in 1:nj
                        yik = yi .- yj[k]
                        vik = vi .- vj[k]
                        wk = ker(vik, h)
                        vik = hcat(ones(ni, 1), vik)
                        res = localLinear_quantReg.solver(yik, vik, wk, m.quantileNum)
                        bij = bij + res[2]
                    end
                    bij = bij / nj
                    A[t, :] = zi - zj
                    b[t] = bij
                    # println(A)
                    # println(b)                    
                    t = t + 1
                # end
            end
        end

            m.beta = pinv(A'*A)*A'*b    
    end

    # function beta_estimator(m::model)
    #     v = m.X*m.theta  + m.Z*m.gamma
    #     n, q = size(m.Z)
    #     h = var(v)*(n)^(m.widthExp)
    #     y = m.y - m.X*m.alpha
    #     gv, dgv, beta = zeros(n), zeros(n), zeros(q)
    #     # nb = 0
    #     for k in 1:n
    #         ind = Vector(1:n)
    #         popat!(ind, k)
    #         vij = v .- v[k]
    #         vij = vij[ind] 
    #         wk = ker(vij, h)        
    #         vk = hcat(ones(n - 1),  vij, m.Z[ind, :] - m.Z[k, :])  # 
    #         b = localLinear_quantReg.solver(y[ind] .- y[k], vk, wk, m.quantileNum)
    #         # println(b)
    #         gv[k], dgv[k] = b[2], b[3]
    #         betak = b[4:end]
    #         # if norm(betak) > 1e-6
    #             beta = beta + betak
    #             # nb = nb + 1
    #         # end
    #         # beta = beta + b[3:end]        
    #     end
    #     m.beta = beta/n
    #     # gv, dgv
    # end



	function Gz(v, vz, yz, d = 1, tau = 0.5, hp = -0.17, method = "gurobi")
		# Estimate Q(y, Z = zk) = g(v + Zk γ)

		nz = length(vz)
		var_v =  std(vz)
		hi = (nz)^(hp)  * var_v 
		ind = Vector(1:nz)
		# popat!(ind, i)
		vzi = vz[ind] .- v
		yzi = yz[ind]
		KerVal = ker.(vzi / hi)/hi
        vzi = reshape(vzi, nz, 1)
        # if d > 0
            vzi = [ones(nz) vzi]
        # else
            # vzi = ones(nz, 1)
        # end
    
    
		wi = localLinear_quantReg.solver(yzi, vzi, KerVal, tau, method)
		res = wi[d + 2]

	end



	function vec_Gz(v, vz, yz, d = 1, tau = 0.5,  hp = -0.17, method = "qr")
		# Estimate Q(y, Z = zk) = g(v + Zk γ)
		# for v, return gz = g.(v) and dgz = ∇g.(v) 

		nz = length(vz)
		nv = length(v)
		Gz = zeros(nv)
        # max_v = maximum(vz)
        # min_v = minimum(vz)
        # widv =   max_v - min_v    
        # vz = ((vz .- min_v) / widv .- 0.5) * 5 
        # v = ((v .- min_v) / widv .- 0.5) * 5
		std_v =  std(vz)
        mean_v = mean(vz)

		h = (nz)^(hp) * std_v 
        # h = (h > 0.17) * h + (h < 0.17) * 0.17
		KerVal = zeros(nz, nv)
			for i in 1:nv
                vzi = vz .- v[i]
				KerVal = ker.(vzi / h)/h
                vzi = [ones(nz) vzi]
                wi = localLinear_quantReg.solver(yz, vzi, KerVal, tau, method)

				Gz[i] = wi[d + 2]

			end

		Gz
	end

    function bandwidth_cv1(m::model, widthExp::Float64) # CV(1) estimationg for bandwidth
        v = m.X * m.theta
		y = m.y - m.X * m.alpha
        ncateg = m.index.count
		n,p = size(m.X)
		res = zeros(n)
		# categ, index = collection(z)
		for k in 1:ncateg
            indk = m.index[m.categ[k]] 
            vz = v[indk]
            yz = y[indk]
            nz = length(vz)
            for j in 1:nz
                indz = Vector(1:nz)
                popat!(indz, j)
                indj = indk[j]
            
                vz_j = vz[indz]
                yz_j = yz[indz]
                res[indj] = Gz(vz[j], vz_j, yz_j, 1, m.quantileNum, widthExp)[1]
            end
        end
        bias = rho.(y .- res, m.quantileNum) |> sum 
        bias = bias / (2n)
    end


    function bandwidth_selection(m::model)
        bw = -0.30:0.015:0.10
        nbw = length(bw)
        bw_path = zeros(nbw)
        for j in 1:nbw
            bw_path[j] = qgplsim.bandwidth_cv1(m, bw[j])
        end
        ind = argmin(bw_path)
        bandwidth_exp = bw[ind]
    end

	function x_estimator_bak(data::model, method)
		X, y, tau = data.X, data.y, data.quantileNum
		
		n, p = size(X)
		categ, index = data.categ, data.index
		ncateg = index.count

		Bz = zeros(n, p)
		for k in 1:ncateg
			z = categ[k]
			indz = index[z]
			nz = length(indz)
			az = zeros(nz)
			yz = y[indz]
			Xz = X[indz, :]
			mean_xz = mean(Xz, dims=1)
			ht = var(Xz, dims = 1)
			h = ones(p) .* nz^(-0.1)
			for i in 1:p
				h[i] = h[i] * ht[i] 

			end

			for i in 1:nz 
				Xzi = Xz[i, :]
				Xi = Xz - (Xzi)
				ind = Vector(1:nz)
				popat!(ind, i)
				Xi = Xi[ind, :]
				yzi = yz[ind]
				KerVal = ker(Xi, h)
                wi = localLinear_quantReg.solver(yzi, Xi, KerVal, tau, 1, method)

				az[i] = wi[1]
				Bz[indz[i],:] = wi[2:end]
			end
		end

		nij = Int(n * (n - 1) / 2)
		bz = zeros(nij, p)
		ij = 1
		for i in 1:n - 1 # Int(n/2)
			for j in (i + 1) : n # (Int(n/2) + 1):n
				bz[ij, :] = Bz[i, :] - Bz[j, :]
				ij = ij + 1

			end
		end
		Rbz = kmeans(bz |> transpose, 2)
       	bz1 = Rbz.centers[:, 1]
        bz2 = Rbz.centers[:, 2]
            
		if bz1[1] > 0
			bz2 = -bz2
		else
			bz1 = -bz1
		end
		sum_Bz = bz1 + bz2
		alpha = sum_Bz / norm(sum_Bz) 

		alpha_t = alpha
		Bz_t = Bz

		C = Bz_t * alpha_t ./ norm(alpha_t)^2
		theta = sum(Bz_t - kron(C , transpose(alpha_t)) , dims = 1)
		theta = theta[1,:] / n
        sg = sign(alpha[1])
		theta .* sg, alpha .* sg, bz1, bz2 # Cz

	end
end # module
